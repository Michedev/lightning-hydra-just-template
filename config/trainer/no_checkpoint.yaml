# PyTorch Lightning Trainer configuration
_target_: pytorch_lightning.Trainer
max_epochs: 50
accelerator: "gpu"  # Options: "cpu", "gpu", "tpu"
devices: 1  # Number of devices to use
log_every_n_steps: 1
gradient_clip_val: null
gradient_clip_algorithm: "norm"
precision: 16  # Options: 32, 16, "bf16"
deterministic: false
check_val_every_n_epoch: 10 # modified by me because maad is very small dataset
# Callbacks configuration
callbacks:
  - _target_: pytorch_lightning.callbacks.LearningRateMonitor
    logging_interval: "epoch"