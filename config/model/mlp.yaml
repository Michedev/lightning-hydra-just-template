_target_: your_codebase.model.mlp.MLPModel

input_size: 784  # e.g., for MNIST 28x28 flattened
hidden_sizes: [256, 128, 64]
output_size: 10  # number of classes
activation: relu
dropout: 0.2
learning_rate: 0.001
